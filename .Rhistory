set.seed(7)
# load the library
library(mlbench)
library(caret)
# load the data
data(PimaIndiansDiabetes)
# calculate correlation matrix
correlationMatrix <- cor(PimaIndiansDiabetes[,1:8])
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.5)
# print indexes of highly correlated attributes
print(highlyCorrelated)
# Cousera Machine Learning Project code
# import training data, note that missing values = NA
dat.train <- read.csv("pml-training.csv",TRUE,sep=",", stringsAsFactors = FALSE)
# import test data
dat.test <- read.csv("pml-testing.csv",TRUE,sep=",", stringsAsFactors = FALSE)
#na.strings="na")
# load packages to fit data
library(caret); library(kernlab); library("e1071"); library(randomForest)
library(dplyr)
set.seed(32343)
# evaluate the data
str(dat.train)
# we can eliminate the X, user_name, kurtosis_yaw_belt, skewness_yaw_belt
# and all the timestamp columns because these add no value
drop_cols <- c('X','user_name','kurtosis_yaw_belt','skewness_yaw_belt','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp')
dat.train <- dat.train[ , !(names(dat.train) %in% drop_cols)]
# run a summary to get a feel for the distribution of values within the variables
summary(dat.train)
# we see a good number of columns that have 19,216 NA values, adding little value
# and they can be eliminated. we'll use 95% NA rate to remove the columns
drop_cols <- which(colSums(dat.train=="" | is.na(dat.train))>0.95*dim(dat.train)[1])
str(drop_cols)
# we end up deleting 31 columns
dat.train <- dat.train[ ,-drop_cols]
# this leaves 122 columns
ncol(dat.train)
# next we eliminate redunant variables by checking for variables
# that are correlated with one another by at least 75% (source: https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/)
# get numeric columns
dat.train.nums <- select_if(dat.train,is.numeric)
# calculate correlation matrix
correlationMatrix <- cor(dat.train.nums)
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
# print indexes of highly correlated attributes
print(highlyCorrelated)
str(highlyCorrelated)
dat.train <- [,-highlyCorrelated]
dat.train <- dat.train[,-highlyCorrelated]
ncol(dat.train)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(classe~., data=dat.train, method="lvq", preProcess="scale", trControl=control)
# Cousera Machine Learning Project code
# import training data, note that missing values = NA
dat.train <- read.csv("pml-training.csv",TRUE,sep=",", stringsAsFactors = FALSE)
# import test data
dat.test <- read.csv("pml-testing.csv",TRUE,sep=",", stringsAsFactors = FALSE)
#na.strings="na")
# load packages to fit data
library(caret); library(kernlab); library("e1071"); library(randomForest)
library(dplyr)
set.seed(32343)
# evaluate the data
str(dat.train)
# we can eliminate the X, user_name, kurtosis_yaw_belt, skewness_yaw_belt
# and all the timestamp columns because these add no value
drop_cols <- c('X','user_name','kurtosis_yaw_belt','skewness_yaw_belt','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp')
dat.train <- dat.train[ , !(names(dat.train) %in% drop_cols)]
# run a summary to get a feel for the distribution of values within the variables
summary(dat.train)
# we see a good number of columns that have 19,216 NA values, adding little value
# and they can be eliminated. we'll use 95% NA rate to remove the columns
drop_cols <- which(colSums(dat.train=="" | is.na(dat.train))>0.95*dim(dat.train)[1])
str(drop_cols)
# we end up deleting 31 columns
dat.train <- dat.train[ ,-drop_cols]
# this leaves 122 columns
ncol(dat.train)
# next we eliminate redunant variables by checking for variables
# that are correlated with one another by at least 75% (source: https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/)
# get numeric columns
dat.train.nums <- select_if(dat.train,is.numeric)
# calculate correlation matrix
correlationMatrix <- cor(dat.train.nums)
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
# remove highly correlated variables
dat.train <- dat.train[,-highlyCorrelated]
nrow(dat.train)
# partition data into train/test. Normally would use 70/30 split, but
# going with 50/50 to save on processing
inTrain <- createDataPartition(y=dat.train$classe,
p=0.5, list=FALSE)
training <- dat.train[inTrain,]
testing <- dat.train[-inTrain,]
dim(training)
table(training$classe)
table(testing$classe)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(classe~., data=training, method="lvq", preProcess="scale", trControl=control)
# Cousera Machine Learning Project code
# import training data, note that missing values = NA
dat.train <- read.csv("pml-training.csv",TRUE,sep=",", stringsAsFactors = FALSE)
# import test data
dat.test <- read.csv("pml-testing.csv",TRUE,sep=",", stringsAsFactors = FALSE)
#na.strings="na")
# load packages to fit data
library(caret); library(kernlab); library("e1071"); library(randomForest)
library(dplyr)
set.seed(32343)
# evaluate the data
str(dat.train)
# we can eliminate the X, user_name, kurtosis_yaw_belt, skewness_yaw_belt
# and all the timestamp columns because these add no value
drop_cols <- c('X','user_name','kurtosis_yaw_belt','skewness_yaw_belt','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp')
dat.train <- dat.train[ , !(names(dat.train) %in% drop_cols)]
# run a summary to get a feel for the distribution of values within the variables
summary(dat.train)
# we see a good number of columns that have 19,216 NA values, adding little value
# and they can be eliminated. we'll use 95% NA rate to remove the columns
drop_cols <- which(colSums(dat.train=="" | is.na(dat.train))>0.95*dim(dat.train)[1])
str(drop_cols)
# we end up deleting 31 columns
dat.train <- dat.train[ ,-drop_cols]
# this leaves 122 columns
ncol(dat.train)
# next we eliminate redunant variables by checking for variables
# that are correlated with one another by at least 75% (source: https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/)
# get numeric columns
dat.train.nums <- select_if(dat.train,is.numeric)
# calculate correlation matrix
correlationMatrix <- cor(dat.train.nums)
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
# remove highly correlated variables
#dat.train <- dat.train[,-highlyCorrelated]
nrow(dat.train)
# partition data into train/test. Normally would use 70/30 split, but
# going with 50/50 to save on processing
inTrain <- createDataPartition(y=dat.train$classe,
p=0.5, list=FALSE)
training <- dat.train[inTrain,]
testing <- dat.train[-inTrain,]
# try random forest
fitControl <- trainControl(method='cv', number = 3)
DT_Model <- train(classe~., data=training, method="rpart", trControl=fitControl)
#  Plot
fancyRpartPlot(DT_Model$finalModel)
library(rpart.plot)
# Cousera Machine Learning Project code
# import training data, note that missing values = NA
dat.train <- read.csv("pml-training.csv",TRUE,sep=",", stringsAsFactors = FALSE)
# import test data
dat.test <- read.csv("pml-testing.csv",TRUE,sep=",", stringsAsFactors = FALSE)
#na.strings="na")
# load packages to fit data
library(caret); library(kernlab); library("e1071"); library(randomForest)
library(dplyr); library(rpart.plot)
set.seed(32343)
# evaluate the data
str(dat.train)
# we can eliminate the X, user_name, kurtosis_yaw_belt, skewness_yaw_belt
# and all the timestamp columns because these add no value
drop_cols <- c('X','user_name','kurtosis_yaw_belt','skewness_yaw_belt','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp')
dat.train <- dat.train[ , !(names(dat.train) %in% drop_cols)]
# run a summary to get a feel for the distribution of values within the variables
summary(dat.train)
# we see a good number of columns that have 19,216 NA values, adding little value
# and they can be eliminated. we'll use 95% NA rate to remove the columns
drop_cols <- which(colSums(dat.train=="" | is.na(dat.train))>0.95*dim(dat.train)[1])
str(drop_cols)
# we end up deleting 31 columns
dat.train <- dat.train[ ,-drop_cols]
# this leaves 122 columns
ncol(dat.train)
# next we eliminate redunant variables by checking for variables
# that are correlated with one another by at least 75% (source: https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/)
# get numeric columns
dat.train.nums <- select_if(dat.train,is.numeric)
# calculate correlation matrix
correlationMatrix <- cor(dat.train.nums)
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
# remove highly correlated variables
#dat.train <- dat.train[,-highlyCorrelated]
nrow(dat.train)
# partition data into train/test. Normally would use 70/30 split, but
# going with 50/50 to save on processing
inTrain <- createDataPartition(y=dat.train$classe,
p=0.5, list=FALSE)
training <- dat.train[inTrain,]
testing <- dat.train[-inTrain,]
# try random forest
fitControl <- trainControl(method='cv', number = 3)
DT_Model <- train(classe~., data=training, method="rpart", trControl=fitControl)
#  Plot
fancyRpartPlot(DT_Model$finalModel)
# Cousera Machine Learning Project code
# import training data, note that missing values = NA
dat.train <- read.csv("pml-training.csv",TRUE,sep=",", stringsAsFactors = FALSE)
# import test data
dat.test <- read.csv("pml-testing.csv",TRUE,sep=",", stringsAsFactors = FALSE)
#na.strings="na")
# load packages to fit data
library(caret); library(kernlab); library("e1071"); library(randomForest)
library(dplyr); library(rpart.plot); library(rpart)
set.seed(32343)
# evaluate the data
str(dat.train)
# we can eliminate the X, user_name, kurtosis_yaw_belt, skewness_yaw_belt
# and all the timestamp columns because these add no value
drop_cols <- c('X','user_name','kurtosis_yaw_belt','skewness_yaw_belt','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp')
dat.train <- dat.train[ , !(names(dat.train) %in% drop_cols)]
# run a summary to get a feel for the distribution of values within the variables
summary(dat.train)
# we see a good number of columns that have 19,216 NA values, adding little value
# and they can be eliminated. we'll use 95% NA rate to remove the columns
drop_cols <- which(colSums(dat.train=="" | is.na(dat.train))>0.95*dim(dat.train)[1])
str(drop_cols)
# we end up deleting 31 columns
dat.train <- dat.train[ ,-drop_cols]
# this leaves 122 columns
ncol(dat.train)
# next we eliminate redunant variables by checking for variables
# that are correlated with one another by at least 75% (source: https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/)
# get numeric columns
dat.train.nums <- select_if(dat.train,is.numeric)
# calculate correlation matrix
correlationMatrix <- cor(dat.train.nums)
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
# remove highly correlated variables
#dat.train <- dat.train[,-highlyCorrelated]
nrow(dat.train)
# partition data into train/test. Normally would use 70/30 split, but
# going with 50/50 to save on processing
inTrain <- createDataPartition(y=dat.train$classe,
p=0.5, list=FALSE)
training <- dat.train[inTrain,]
testing <- dat.train[-inTrain,]
# try random forest
fitControl <- trainControl(method='cv', number = 3)
DT_Model <- train(classe~., data=training, method="rpart", trControl=fitControl)
#  Plot
fancyRpartPlot(DT_Model$finalModel)
rpart.plot(DT_Model)
# Cousera Machine Learning Project code
# import training data, note that missing values = NA
dat.train <- read.csv("pml-training.csv",TRUE,sep=",", stringsAsFactors = FALSE)
# import test data
dat.test <- read.csv("pml-testing.csv",TRUE,sep=",", stringsAsFactors = FALSE)
#na.strings="na")
# load packages to fit data
library(caret); library(kernlab); library("e1071"); library(randomForest)
library(dplyr); library(rpart.plot); library(rpart); library(rattle)
set.seed(32343)
# evaluate the data
str(dat.train)
# we can eliminate the X, user_name, kurtosis_yaw_belt, skewness_yaw_belt
# and all the timestamp columns because these add no value
drop_cols <- c('X','user_name','kurtosis_yaw_belt','skewness_yaw_belt','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp')
dat.train <- dat.train[ , !(names(dat.train) %in% drop_cols)]
# run a summary to get a feel for the distribution of values within the variables
summary(dat.train)
# we see a good number of columns that have 19,216 NA values, adding little value
# and they can be eliminated. we'll use 95% NA rate to remove the columns
drop_cols <- which(colSums(dat.train=="" | is.na(dat.train))>0.95*dim(dat.train)[1])
str(drop_cols)
# we end up deleting 31 columns
dat.train <- dat.train[ ,-drop_cols]
# this leaves 122 columns
ncol(dat.train)
# next we eliminate redunant variables by checking for variables
# that are correlated with one another by at least 75% (source: https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/)
# get numeric columns
dat.train.nums <- select_if(dat.train,is.numeric)
# calculate correlation matrix
correlationMatrix <- cor(dat.train.nums)
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
# remove highly correlated variables
#dat.train <- dat.train[,-highlyCorrelated]
nrow(dat.train)
# partition data into train/test. Normally would use 70/30 split, but
# going with 50/50 to save on processing
inTrain <- createDataPartition(y=dat.train$classe,
p=0.5, list=FALSE)
training <- dat.train[inTrain,]
testing <- dat.train[-inTrain,]
# try random forest
fitControl <- trainControl(method='cv', number = 3)
DT_Model <- train(classe~., data=training, method="rpart", trControl=fitControl)
#  Plot
fancyRpartPlot(DT_Model$finalModel)
# Cousera Machine Learning Project code
# import training data, note that missing values = NA
dat.train <- read.csv("pml-training.csv",TRUE,sep=",", stringsAsFactors = FALSE)
# import test data
dat.test <- read.csv("pml-testing.csv",TRUE,sep=",", stringsAsFactors = FALSE)
#na.strings="na")
# load packages to fit data
library(caret); library(kernlab); library("e1071"); library(randomForest)
library(dplyr); library(rpart.plot); library(rpart); library(rattle)
set.seed(32343)
# evaluate the data
str(dat.train)
# we can eliminate the X, user_name, kurtosis_yaw_belt, skewness_yaw_belt
# and all the timestamp columns because these add no value
drop_cols <- c('X','user_name','kurtosis_yaw_belt','skewness_yaw_belt','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp')
dat.train <- dat.train[ , !(names(dat.train) %in% drop_cols)]
# run a summary to get a feel for the distribution of values within the variables
summary(dat.train)
# we see a good number of columns that have 19,216 NA values, adding little value
# and they can be eliminated. we'll use 95% NA rate to remove the columns
drop_cols <- which(colSums(dat.train=="" | is.na(dat.train))>0.95*dim(dat.train)[1])
str(drop_cols)
# we end up deleting 31 columns
dat.train <- dat.train[ ,-drop_cols]
# this leaves 122 columns
ncol(dat.train)
# next we eliminate redunant variables by checking for variables
# that are correlated with one another by at least 75% (source: https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/)
# get numeric columns
dat.train.nums <- select_if(dat.train,is.numeric)
# calculate correlation matrix
correlationMatrix <- cor(dat.train.nums)
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
# remove highly correlated variables
dat.train <- dat.train[,-highlyCorrelated]
nrow(dat.train)
# partition data into train/test. Normally would use 70/30 split, but
# going with 50/50 to save on processing
inTrain <- createDataPartition(y=dat.train$classe,
p=0.5, list=FALSE)
training <- dat.train[inTrain,]
testing <- dat.train[-inTrain,]
# try random forest
fitControl <- trainControl(method='cv', number = 3)
DT_Model <- train(classe~., data=training, method="rpart", trControl=fitControl)
#  Plot
fancyRpartPlot(DT_Model$finalModel)
DT_Predict <- predict(DT_Model,newdata=testing)
DT_cm <- confusionMatrix(TestData$classe,DT_Predict)
DT_Predict <- predict(DT_Model,newdata=testing)
DT_cm <- confusionMatrix(testing$classe,DT_Predict)
head(DT_Predict)
dim(DT_Predict)
str(DT_Predict)
str(testing$classe)
DT_Predict <- as.character(DT_Predict)
str(DT_Predict)
DT_Predict <- as.character(predict(DT_Model,newdata=testing))
DT_cm <- confusionMatrix(testing$classe,DT_Predict)
str(DT_Predict)
DT_Predict <- predict(DT_Model,newdata=testing)
DT_cm <- confusionMatrix(as.factor(testing$classe),DT_Predict)
DT_cm
RF_Model <- train(classe~., data=training, method="rf", trControl=fitControl, verbose=FALSE)
# Plot
plot(RF_Model,main="RF Model Accuracy by number of predictors")
RF_Predict <- predict(RF_Model,newdata=TestData)
RF_cm <- confusionMatrix(TestData$classe,RF_Predict)
# Display confusion matrix and model accuracy
RF_cm
RF_Predict <- predict(RF_Model,newdata=testing)
RF_cm <- confusionMatrix(testing$classe,RF_Predict)
# Display confusion matrix and model accuracy
RF_cm
RF_Predict <- predict(RF_Model,newdata=testing)
RF_cm <- confusionMatrix(as.factor(testing$classe),RF_Predict)
# Display confusion matrix and model accuracy
RF_cm
GBM_Model <- train(classe~., data=TrainData, method="gbm", trControl=fitControl, verbose=FALSE)
#  Plot
plot(GBM_Model)
GBM_Model <- train(classe~., data=training, method="gbm", trControl=fitControl, verbose=FALSE)
#  Plot
plot(GBM_Model)
GBM_Predict <- predict(GBM_Model,newdata=TestData)
GBM_cm <- confusionMatrix(testing$classe,GBM_Predict)
# Display confusion matrix and model accuracy
GBM_cm
GBM_Predict <- predict(GBM_Model,newdata=testing)
GBM_cm <- confusionMatrix(testing$classe,GBM_Predict)
# Display confusion matrix and model accuracy
GBM_cm
# Testing the model
GBM_Predict <- predict(GBM_Model,newdata=testing)
GBM_cm <- confusionMatrix(as.factor(testing$classe),GBM_Predict)
# Display confusion matrix and model accuracy
GBM_cm
modFit <- train(classe ~ .,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
fancyRpartPlot(modFit$finalModel)
mod_rpart <- train(classe ~ .,method="rpart",data=training)
print(mod_rpart$finalModel)
fancyRpartPlot(mod_rpart$finalModel)
# Predict and create confusion matrix
pred_cm <- predict(mod_rpart,newdata=testing)
cm_rpart <- confusionMatrix(as.factor(testing$classe),pred_cm)
cm_rpart
RF_Model <- train(Species~ .,data=training,method="rf",prox=TRUE)
#RF_Model <- train(classe~., data=training, method="rf", trControl=fitControl, verbose=FALSE)
# Plot
plot(RF_Model,main="RF Model Accuracy by number of predictors")
#next, we rank feature by importance since there are still 34 variables
# Testing the model
RF_Predict <- predict(RF_Model,newdata=testing)
RF_cm <- confusionMatrix(as.factor(testing$classe),RF_Predict)
RF_Model <- train(classe~ .,data=training,method="rf",prox=TRUE)
fitControl <- trainControl(method='cv', number = 3)
mod_rf <- train(classe~., data=training, method="rf", trControl=fitControl, verbose=FALSE)
rm(list = ls())
# Cousera Machine Learning Project code
# import training data, note that missing values = NA
dat.train <- read.csv("pml-training.csv",TRUE,sep=",", stringsAsFactors = FALSE)
# import test data
dat.test <- read.csv("pml-testing.csv",TRUE,sep=",", stringsAsFactors = FALSE)
#na.strings="na")
# load packages to fit data
library(caret); library(kernlab); library("e1071"); library(randomForest)
library(dplyr); library(rpart.plot); library(rpart); library(rattle)
set.seed(32343)
# evaluate the data
str(dat.train)
# we can eliminate the X, user_name, kurtosis_yaw_belt, skewness_yaw_belt
# and all the timestamp columns because these add no value
drop_cols <- c('X','user_name','kurtosis_yaw_belt','skewness_yaw_belt','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp')
dat.train <- dat.train[ , !(names(dat.train) %in% drop_cols)]
# run a summary to get a feel for the distribution of values within the variables
summary(dat.train)
# we see a good number of columns that have 19,216 NA values, adding little value
# and they can be eliminated. we'll use 95% NA rate to remove the columns
drop_cols <- which(colSums(dat.train=="" | is.na(dat.train))>0.95*dim(dat.train)[1])
str(drop_cols)
# we end up deleting 31 columns
dat.train <- dat.train[ ,-drop_cols]
# this leaves 122 columns
ncol(dat.train)
# next we eliminate redunant variables by checking for variables
# that are correlated with one another by at least 75% (source: https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/)
# get numeric columns
dat.train.nums <- select_if(dat.train,is.numeric)
# calculate correlation matrix
correlationMatrix <- cor(dat.train.nums)
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
# remove highly correlated variables
dat.train <- dat.train[,-highlyCorrelated]
nrow(dat.train)
# partition data into train/test. Normally would use 70/30 split, but
# going with 50/50 to save on processing
inTrain <- createDataPartition(y=dat.train$classe,
p=0.5, list=FALSE)
training <- dat.train[inTrain,]
testing <- dat.train[-inTrain,]
# decision tree example
mod_rpart <- train(classe ~ .,method="rpart",data=training)
print(mod_rpart$finalModel)
fancyRpartPlot(mod_rpart$finalModel)
# Predict and create confusion matrix
pred_cm <- predict(mod_rpart,newdata=testing)
cm_rpart <- confusionMatrix(as.factor(testing$classe),pred_cm)
cm_rpart
# Try random forest
fitControl <- trainControl(method='cv', number = 3)
mod_rf <- train(classe~., data=training, method="rf", trControl=fitControl, verbose=FALSE)
# Plot
plot(mod_rf,main="RF Model Accuracy by number of predictors")
pred_rf <- predict(mod_rf,newdata=testing)
cm_rf <- confusionMatrix(as.factor(testing$classe),pred_rf)
# Display confusion matrix and model accuracy
cm_rf
mod_gbm <- train(classe~., data=training, method="gbm", trControl=fitControl, verbose=FALSE)
#  Plot
plot(mod_gbm)
# Testing the model
pred_gbm <- predict(mod_gbm,newdata=testing)
cm_gbm <- confusionMatrix(as.factor(testing$classe),pred_gbm)
# Display confusion matrix and model accuracy
cm_gbm
# We see that the general boosting model offers the highest accuracy.
# Next we predict the 20 sample cases by using the general boosting
# model.
test_final <- predict(mod_rf,newdata=dat.test)
test_final
